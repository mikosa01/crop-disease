{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/kf/yv1zrfvd701c47vqp5xz4sjh0000gn/T/ipykernel_3837/3624518383.py:1: DeprecationWarning: \n",
      "Pyarrow will become a required dependency of pandas in the next major release of pandas (pandas 3.0),\n",
      "(to allow more performant data types, such as the Arrow string type, and better interoperability with other libraries)\n",
      "but was not found to be installed on your system.\n",
      "If this would cause problems for you,\n",
      "please provide us feedback at https://github.com/pandas-dev/pandas/issues/54466\n",
      "        \n",
      "  import pandas as pd\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd \n",
    "import os\n",
    "import torch\n",
    "from torch.utils.data import DataLoader, random_split\n",
    "from torch import nn as nn\n",
    "import  torch.optim as optim\n",
    "from torchvision.datasets import ImageFolder\n",
    "from torchvision import  transforms\n",
    "from torchvision.transforms import functional\n",
    "from torchvision.models import resnet18, ResNet18_Weights\n",
    "from PIL import Image\n",
    "from torchmetrics import Recall, Precision, Accuracy, AUROC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3\n"
     ]
    }
   ],
   "source": [
    "img = Image.open('data/train_images/6103.jpg')\n",
    "num_channels = functional.get_image_num_channels(img)\n",
    "print(num_channels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ImageDataset: \n",
    "    def __init__(self, csv_path, image_dir, transform):\n",
    "        self.data = pd.read_csv(csv_path)\n",
    "        self.image_dir = image_dir\n",
    "        self.transform = transform\n",
    "        self.data = self.data[self.data['image_id'].apply(lambda x: os.path.exists(os.path.join(self.image_dir, x)))]\n",
    "        # self.data = self.data.map({\"0\": \"Cassava Bacterial Blight (CBB)\", \n",
    "        #                         \"1\": \"Cassava Brown Streak Disease (CBSD)\", \n",
    "        #                         \"2\": \"Cassava Green Mottle (CGM)\", \n",
    "        #                         \"3\": \"Cassava Mosaic Disease (CMD)\", \n",
    "        #                         \"4\": \"Healthy\"})\n",
    "\n",
    "\n",
    "    def __len__(self): \n",
    "        return len(self.data)\n",
    "    \n",
    "    def __getitem__(self, idx): \n",
    "        image_name = os.path.join(self.image_dir, self.data.iloc[idx, 0])\n",
    "  \n",
    "        \n",
    "        label = self.data.iloc[idx, 1]\n",
    "\n",
    "        image = Image.open(image_name)\n",
    "        \n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "    \n",
    "        return image, label "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "transforma = transforms.Compose([\n",
    "    transforms.Resize((64, 64)),        # Resize images to 128x128\n",
    "    transforms.ToTensor(),                # Convert to tensor\n",
    "    transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))  # Normalize with mean & std\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "weights = ResNet18_Weights.DEFAULT\n",
    "model = resnet18(weights=weights)\n",
    "transform = weights.transforms()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_dir = 'data/train_images'\n",
    "csv_dir = 'data/train.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "files = ImageDataset(csv_path=csv_dir, image_dir=img_dir, transform=transforma)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_size = int(0.8 * len(files))\n",
    "test_size = len(files) - train_size\n",
    "\n",
    "train_dataset, test_dataset = random_split(files, [train_size, test_size])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = DataLoader(dataset=train_dataset, batch_size=32, shuffle=True)\n",
    "test_loader = DataLoader(dataset=test_dataset, batch_size=32, shuffle=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for x, y in train_loader: \n",
    "#    print(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "crtiterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr = 0.0001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# acc = Accuracy(task='multiclass', num_classes=5, average= 'weighted')\n",
    "# pre = Precision(task='multiclass', num_classes=5, average='weighted')\n",
    "# recall = Recall(task='multiclass', num_classes=5, average='weighted')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/4], Loss: 0.0013\n",
      "Epoch [2/4], Loss: 0.0006\n",
      "Epoch [3/4], Loss: 0.0002\n",
      "Epoch [4/4], Loss: 0.0002\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = model.to(device)\n",
    "\n",
    "for epoch in range(4): \n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    for feature, label in train_dataset:\n",
    "        # feature, label = feature.to(device), label.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        pred = model(feature.unsqueeze(0)).squeeze(0)\n",
    "        loss = crtiterion(pred, torch.tensor(label))\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    running_loss += loss.item()\n",
    "    print(f\"Epoch [{epoch+1}/{4}], Loss: {running_loss/len(train_loader):.4f}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tensor",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
